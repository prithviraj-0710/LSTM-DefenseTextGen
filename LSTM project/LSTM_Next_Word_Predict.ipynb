{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce3c777f-791e-4880-a386-dd84bac7cbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "drdo=\"\"\"Predictive Factor Analysis of Air-to-Air Engagement Outcomes Using Air Combat Manoeuvring Instrumentation Data\n",
    "Air superiority is essential in modern warfare1-3. Air superiority refers to controlling the battlefield sky against an enemy. Once air superiority is achieved, friendly forces, including ground forces, can manoeuvre without prohibitive interference from enemy forces4,5. Air combat is a tactical method used to achieve air superiority, and various studies have been conducted to improve its efficiency6-9. In this study, we focus on the critical factors of air combat against an enemy’s aerial vehicle regarding Air Combat Manoeuvres (ACM). Regarding ACM, it is essential to develop effective combat tactics and train fighter pilots to improve the win rate in air-to-air combat. However, due to costs, the use of fighters and weapons for developing or evaluating tactics and training or testing pilot skills is limited10. Thus, air-to-air combat training is mostly conducted in virtual environments, and the development of precise ACM performance measurements is becoming increasingly important to ensure the reliability of air combat tactics and pilot skills in real-world scenarios. Existing research approaches to ACM performance measurements mainly focus on combining analytical and empirical methodologies to develop appropriate measurement structures and algorithms11. Candidate measurements such as positional advantage and weapon events have been developed based on the state information of both aircraft and weapons, and various studies have utilised these candidates12-17. Waag18 , et al. proposed a composite measure to predict engagement outcomes during ACM. Krusmark12, et al. assessed the effectiveness of the traditional Grade sheet used to measure air-combat performance. ARAR19, et al. proposed a flexible rule-based framework for a pilot performance analysis. However, while the utility and effectiveness of both simulation systems and ACM performance measurements have been demonstrated regarding training fighter pilots and developing air combat tactics, more debate still needs to be had on their reliability and validity in real-world environments20-21 . Balcerzak22, et al. insisted that there was a shortage of research demonstrating the validity of simulation systems, citing the case of civilian aircraft, and that it was more apparent whether the skills learned in simulations were appropriately applied to actual flights. This debate has significant implications for the military domain. Therefore, providing feedback based on actual manoeuvring track data analysis is essential for calibrating measurements developed in a virtual environment. However, a statistical approach to ACM based on actual data has rarely been studied in this domain because acquiring the actual manoeuvring data of an aircraft is limited because of cost and safety concerns.\n",
    "Air Combat Manoeuvring Instrumentation (ACMI) systems may be an alternative to resolve these limitations. An ACMI system records in-flight data, such as positional information, aircraft state, and weapon events, using pod devices attached to the aircraft, and the recorded data are used for debriefing. The system consists of aircraft pods and a ground system. ACM data are transmitted from the pod to the ground system for recording, displaying, and debriefing23. In addition, these data have been consistently accumulated and managed for over a decade. Thus, given the various attributes and quantities of ACMI data, they can be used in data-driven research24-25 . Motivated by the need for more realistic and data-driven analyses of air combat engagements, this study presents a comprehensive study based on extensive real-world ACMI data from training engagements. Our objectives are threefold: First, to demonstrate a standard procedure for utilising ACMI system data, encompassing feature extraction, selection, and effective modelling of a hit-prediction problem. Second, an airto-air engagement hit prediction model was constructed using machine learning algorithms, which allowed us to determine the most dominant components of the ACM in deciding engagement outcomes. Third, interpretable machine-learning techniques were applied to rank the key factors for successful engagement. We analyze feature importance using correlation coefficients, feature importance scores, and SHAP (SHapley Additive exPlanations) values26. This approach also allowed us to validate conventional methods, differentiating our work from previous studies that relied primarily on simulated or limited flight test data. The ACMI data are provided by the Republic of Korea Air Force (ROKAF) for research purposes only and are not publicly accessible. The remainder of this paper is organized as follows. Section 2 describes the problem definition and data. Sections 3 and 4 demonstrate the results of feature engineering and the analysis details, respectively, followed by a discussion and conclusion in Section 5.\n",
    "According to the ROKAF training protocol, air-to-air combat training can be divided into the five categories listed in Table 1. This study only focused on the BFM training procedure. Let BLUE be a fighter of friendly forces and RED\n",
    "be an adversarial fighter in an air combat training scenario. BLUE and RED are the same type of fighter, F-16, who engage in Within-Visual Range (WVR) combat. BLUE fires AIM-9 IR (infrared) tracking-guided air-to-air missiles to shoot down RED27. During training, the ACMI pods collected the maneuvering data of both aircraft, except for the RED probability of kill (PK) value. The PK value, which represents the extent to which BLUE’s missile damages RED and ranges from 0 to 1, was calculated internally using the ACMI system. This calculation method has not yet been publicly disclosed. Thus, this study assumed that the PK value calculated by the system adequately reflects the damage to the actual air-to-air engagement. Based on maneuvering data and PK values, we formulate the hit-prediction model to predict a ‘Hit’ or ‘Miss’ from the maneuvering and weapon event data of BLUE and RED. The ‘0’ PK value indicates ‘Miss,’ which means no damage to RED, and the others are converted to ‘Hit,’ which means sufficient damage to RED. The distribution of PK values and the distribution of ‘Hit’ and ‘Miss’ are shown in Fig. 1. The data for training the hit prediction model were obtained from the ACMI system operated by the ROKAF, where the collection period was from 2009 to 2019. To prepare the data, we applied several pre-processing steps. First, we addressed data quality issues by removing outliers and missing data points, which often result from the highspeed data acquisition inherent to the ACMI system. Next, data consistency was ensured by standardizing the units of speed and angle across all attributes. However, we did not perform data normalization because the machine-learning algorithms employed were designed to appropriately handle varying scales of input features. After pre-processing, the dataset contains 2,258 instances corresponding to 2,258 missile launches (hits or misses). Of the total, 1,721 instances were labeled as ‘Hit’ and 537 as ‘Miss,’ yielding a hit ratio of 76.2 % and establishing the baseline performance. Table 2 lists the 18 attributes used in this study.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e38284c-a5aa-4e3b-a474-423913d5de7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf8a2c9d-5487-452c-963c-64a4146649a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4eef57c6-b07a-4415-85bd-7bcb891a9e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "46da0d3c-39fd-440b-b260-0c2db9642772",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts([drdo])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6e77ca09-6bc8-4a63-bc63-134e5f12804c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "479"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0438a1bc-efeb-41cb-9aab-350f97cc7494",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences=[]\n",
    "for sentence in drdo.split('\\n'):\n",
    "    tokenized_sentence=tokenizer.texts_to_sequences([sentence])[0]\n",
    "\n",
    "    for i in range(1,len(tokenized_sentence)):\n",
    "        input_sequences.append(tokenized_sentence[:i+1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "828acae7-5ac7-41be-81d7-7685ccd2c1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "411"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len=max([len(x) for x in input_sequences])\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ec202215-6014-4fa3-87f2-fd5d9aa20394",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "padded_input_sequences=pad_sequences(input_sequences,maxlen=max_len,padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "50e0e894-7c2d-44e6-8295-b7d224b1dfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ...,   0, 157, 158],\n",
       "       [  0,   0,   0, ..., 157, 158,  45],\n",
       "       [  0,   0,   0, ..., 158,  45,   4],\n",
       "       ...,\n",
       "       [  0,   0,   0, ...,  80,  35,   7],\n",
       "       [  0,   0,   0, ...,  35,   7,  12],\n",
       "       [  0,   0,   0, ...,   7,  12,  26]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ddfe3ec-c1cd-4d13-9fc0-359b86bbf27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=padded_input_sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "82a21731-d679-4e77-950b-38273c266546",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=padded_input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "91bd0356-417f-466d-94e0-072214869037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 410)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "059abbb2-04e6-4120-8929-f24e412623c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128,)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "55af9cba-af1f-4ae7-9573-86dff86d0f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y=to_categorical(y,num_classes=480)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9cc4ad49-dc2c-46b4-abec-114b4b8a797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1128, 480)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "de99652d-3c29-4fb3-a298-a9ec0e063799",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Embedding,LSTM,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97a94c1b-7e81-43b5-93fd-819221a8f314",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=480, output_dim=300, input_length=410))  # Added input_length\n",
    "model.add(LSTM(256)) # No need for input_shape here\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(480, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ab12e32b-b6ab-4673-8f2e-c6572b3bcc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4e97af01-04e1-42ca-acda-3e8808e6d2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ ?                      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)         │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ ?                      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7f961a18-0a9b-47b8-82f8-9c9688bb083a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 577ms/step - accuracy: 0.0331 - loss: 6.0663\n",
      "Epoch 2/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 803ms/step - accuracy: 0.0497 - loss: 5.6204\n",
      "Epoch 3/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 794ms/step - accuracy: 0.0634 - loss: 5.5354\n",
      "Epoch 4/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 799ms/step - accuracy: 0.0633 - loss: 5.4905\n",
      "Epoch 5/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 805ms/step - accuracy: 0.0706 - loss: 5.3349\n",
      "Epoch 6/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 809ms/step - accuracy: 0.1157 - loss: 5.1615\n",
      "Epoch 7/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 802ms/step - accuracy: 0.1568 - loss: 4.8394\n",
      "Epoch 8/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 749ms/step - accuracy: 0.1675 - loss: 4.4397\n",
      "Epoch 9/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 795ms/step - accuracy: 0.1987 - loss: 4.1750\n",
      "Epoch 10/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 784ms/step - accuracy: 0.2402 - loss: 3.7308\n",
      "Epoch 11/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 808ms/step - accuracy: 0.3190 - loss: 3.2275\n",
      "Epoch 12/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 797ms/step - accuracy: 0.3951 - loss: 2.8252\n",
      "Epoch 13/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 807ms/step - accuracy: 0.4732 - loss: 2.4240\n",
      "Epoch 14/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 815ms/step - accuracy: 0.5582 - loss: 2.1418\n",
      "Epoch 15/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m114s\u001b[0m 3s/step - accuracy: 0.6374 - loss: 1.7559\n",
      "Epoch 16/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 789ms/step - accuracy: 0.7530 - loss: 1.4661\n",
      "Epoch 17/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 787ms/step - accuracy: 0.7942 - loss: 1.2721\n",
      "Epoch 18/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 805ms/step - accuracy: 0.8635 - loss: 1.0601\n",
      "Epoch 19/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 807ms/step - accuracy: 0.9106 - loss: 0.8699\n",
      "Epoch 20/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 805ms/step - accuracy: 0.9391 - loss: 0.6811\n",
      "Epoch 21/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 789ms/step - accuracy: 0.9499 - loss: 0.6315\n",
      "Epoch 22/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 799ms/step - accuracy: 0.9706 - loss: 0.5165\n",
      "Epoch 23/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 798ms/step - accuracy: 0.9851 - loss: 0.4378\n",
      "Epoch 24/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 802ms/step - accuracy: 0.9880 - loss: 0.3710\n",
      "Epoch 25/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 806ms/step - accuracy: 0.9907 - loss: 0.3246\n",
      "Epoch 26/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 791ms/step - accuracy: 0.9873 - loss: 0.2912\n",
      "Epoch 27/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 793ms/step - accuracy: 0.9887 - loss: 0.2660\n",
      "Epoch 28/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 801ms/step - accuracy: 0.9961 - loss: 0.2394\n",
      "Epoch 29/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 798ms/step - accuracy: 0.9964 - loss: 0.2041\n",
      "Epoch 30/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 794ms/step - accuracy: 0.9932 - loss: 0.1772\n",
      "Epoch 31/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 787ms/step - accuracy: 0.9961 - loss: 0.1723\n",
      "Epoch 32/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 786ms/step - accuracy: 0.9979 - loss: 0.1515\n",
      "Epoch 33/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 797ms/step - accuracy: 0.9985 - loss: 0.1381\n",
      "Epoch 34/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 797ms/step - accuracy: 0.9988 - loss: 0.1251\n",
      "Epoch 35/35\n",
      "\u001b[1m36/36\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 807ms/step - accuracy: 0.9986 - loss: 0.1182\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x271b049c380>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,y,epochs=35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bcca038c-568e-47e9-93be-444c809c4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_predict(text):\n",
    "    for i in range(4):\n",
    "      # tokenize\n",
    "      token_text = tokenizer.texts_to_sequences([text])[0]\n",
    "      # padding\n",
    "      padded_token_text = pad_sequences([token_text], maxlen=56, padding='pre')\n",
    "      # predict\n",
    "      pos = np.argmax(model.predict(padded_token_text))\n",
    "    \n",
    "      for word,index in tokenizer.word_index.items():\n",
    "        if index == pos:\n",
    "          text = text + \" \" + word\n",
    "          print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "32935ac0-3053-4d44-9840-297a825909d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
      "Air Combat manoeuvring\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Air Combat manoeuvring instrumentation\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
      "Air Combat manoeuvring instrumentation acmi\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Air Combat manoeuvring instrumentation acmi systems\n"
     ]
    }
   ],
   "source": [
    "word_predict(\"Air Combat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1b1d17e8-2673-40e8-a9ac-866c99b36298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Rokaf training\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step\n",
      "Rokaf training protocol\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
      "Rokaf training protocol air\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Rokaf training protocol air combat\n"
     ]
    }
   ],
   "source": [
    "word_predict(\"Rokaf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ca31d4b4-1fbc-442c-b35b-e5f55189efbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n",
      "Predictive factor\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
      "Predictive factor analysis\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n",
      "Predictive factor analysis of\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "Predictive factor analysis of air\n"
     ]
    }
   ],
   "source": [
    "word_predict(\"Predictive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711065a4-7b41-429a-8bd3-46812e82c0a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
